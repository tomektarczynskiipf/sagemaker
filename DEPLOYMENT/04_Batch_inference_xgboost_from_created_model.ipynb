{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe7d14f-448a-44fe-9ebc-a6cbb7308b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09580e91-314b-44dc-b19f-132d10d8fe2a",
   "metadata": {},
   "source": [
    "SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5427e885-749c-4a30-8f93-8606189ea828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables (replace these with your actual values)\n",
    "model_name =\"my-xgboost-model-from-training-job\"  # The name of your existing model\n",
    "transform_job_name = 'my-fancy-name'\n",
    "input_data_path = 's3://sagemaker-bucket-ds/training-jobs/data/inference_input/'\n",
    "output_data_path = 's3://sagemaker-bucket-ds/training-jobs/data/inference_output/'\n",
    "instance_type = 'ml.m5.large'  # Replace with your preferred instance type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc662278-f4c7-4e0b-be3a-c461999d6c31",
   "metadata": {},
   "source": [
    "DELETE THE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b327727-ac86-4d62-b949-f7dd3403a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm s3://sagemaker-bucket-ds/training-jobs/data/inference_output/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c983cac-cb5c-4ec9-8b16-43c471dca5e2",
   "metadata": {},
   "source": [
    "BASIC OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0d65db-254d-4b48-be9f-3b0e7d4224bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()  # You can also specify the role ARN directly\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf0ab7-9356-456b-8819-a26b33ac66f1",
   "metadata": {},
   "source": [
    "CREATE TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73967918-a443-4cf2-9aff-56defd632a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer object directly using the existing model name\n",
    "transformer = Transformer(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_data_path,\n",
    "    assemble_with='Line',\n",
    "    accept='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e637f-a26d-44e2-a740-2d64616c7a14",
   "metadata": {},
   "source": [
    "MAKE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68370b8c-0ae1-4f2c-be93-e3613a47babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-07-01-12-32-33-606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:25:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Listening at: unix:/tmp/gunicorn.sock (16)\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\n",
      "\u001b[34m[2024-07-01:12:37:33:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"POST /invocations HTTP/1.1\" 200 628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:33:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"POST /invocations HTTP/1.1\" 200 628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-07-01T12:37:33.298:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:25:INFO] nginx config: \u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:25:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Listening at: unix:/tmp/gunicorn.sock (16)\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [16] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2024-07-01 12:37:25 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-07-01 12:37:25 +0000] [16] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-07-01 12:37:25 +0000] [16] [INFO] Listening at: unix:/tmp/gunicorn.sock (16)\u001b[0m\n",
      "\u001b[35m[2024-07-01 12:37:25 +0000] [16] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2024-07-01 12:37:25 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m[2024-07-01 12:37:25 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:26:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:26:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:26:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:27:INFO] Loading the model from /opt/ml/model/model.xgb\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:33:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-07-01:12:37:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"POST /invocations HTTP/1.1\" 200 628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:33:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-07-01:12:37:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:12:37:33 +0000] \"POST /invocations HTTP/1.1\" 200 628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-07-01T12:37:33.298:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Transform job completed. Output stored in: s3://sagemaker-bucket-ds/training-jobs/data/inference_output/\n"
     ]
    }
   ],
   "source": [
    "# Start the batch transform job\n",
    "transformer.transform(\n",
    "    data=input_data_path,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")\n",
    "\n",
    "# Wait for the transform job to complete\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Transform job completed. Output stored in:\", output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae390394-efec-4b27-995b-fb7d78693b8a",
   "metadata": {},
   "source": [
    "MAKE TRANSFORMATION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

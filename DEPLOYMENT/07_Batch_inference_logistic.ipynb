{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10530f51-3dca-4709-b4bf-944879b033cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.model import SKLearnModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbb1da-dd9a-4736-9424-977f6e52372a",
   "metadata": {},
   "source": [
    "SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06f04d1-0592-4703-817a-9eb75ee4f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the S3 path where the trained model is stored\n",
    "model_data = 's3://sagemaker-eu-west-1-211125740051/trainin-job-simple-03-2024-07-01-13-12-35-409/output/model.tar.gz' # This path can be retreived from training job\n",
    "input_path = 's3://sagemaker-bucket-ds/training-jobs/data/inference_input/'\n",
    "output_path = 's3://sagemaker-bucket-ds/training-jobs/data/inference_output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79c617-1b88-484d-b403-29275f0e2854",
   "metadata": {},
   "source": [
    "DELETE OUTPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab12e15-2dc6-4b10-9018-80e21f1491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm s3://sagemaker-bucket-ds/training-jobs/data/inference_output/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf11da-5402-4dae-97b9-db154c4da7ce",
   "metadata": {},
   "source": [
    "CREATE BASIC OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "312a54a3-e053-46d2-9e31-b275a11854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160e7695-efde-49c7-bafb-29e2b7417408",
   "metadata": {},
   "source": [
    "CREATE ENTRY POINT\n",
    "\n",
    "For some reason the Sklearn docker containers do not implement a function to read the model.\n",
    "That is why we have to define this function by ourselves. Its signature must match the one below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e69f1d27-898e-4b75-a49c-fd0806712b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"07_batch_inference\", exist_ok=True) # Create folder for training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1667feb1-3b16-476a-a22b-dea3f6aaa9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 07_batch_inference/start_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 07_batch_inference/start_file.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# There is no default function to load the model\n",
    "# Without this function the job will fail!\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "# There is a default function to calculate the predictions.\n",
    "# It calculates the class 0/1 instead of probability\n",
    "# That is why we should override it with a custom function\n",
    "def predict_fn(input_data, model):\n",
    "    pred_prob = model.predict_proba(input_data)\n",
    "    return pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a50150-7d26-48e8-881e-1a05a3374e5c",
   "metadata": {},
   "source": [
    "CREATE SKLEARN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3382cce2-a8a3-4284-ae3f-dda274369777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SKLearnModel\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_data,\n",
    "    entry_point='start_file.py', # The file with the training code\n",
    "    source_dir='07_batch_inference', # The folder with the training code\n",
    "    role=role,\n",
    "    framework_version='1.2-1',  # Replace with the appropriate sklearn version\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae52e1-2dba-455b-ade7-f722718c8dfb",
   "metadata": {},
   "source": [
    "CREATE TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16fa05f6-db87-4f97-b828-2e0c48d7e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2024-07-01-14-42-23-782\n"
     ]
    }
   ],
   "source": [
    "# Create the transformer object for batch transform\n",
    "transformer = sklearn_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=output_path # The path where the results will be saved\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08977f80-b85f-44d5-ba3b-d4eec9697bad",
   "metadata": {},
   "source": [
    "CALCULATE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "211312f7-134d-43cf-98ee-b6aeacb638f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-scikit-learn-2024-07-01-14-42-25-502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m2024-07-01 14:47:40,788 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:40,792 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:40,793 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,040 INFO - sagemaker-containers - Module start_file does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: start-file\n",
      "  Building wheel for start-file (setup.py): started\n",
      "  Building wheel for start-file (setup.py): finished with status 'done'\n",
      "  Created wheel for start-file: filename=start_file-1.0.0-py2.py3-none-any.whl size=3250 sha256=50578edfd4dba8b2a6bea5b2b724786f6364aa2126173953256fbb00bd71bdb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-om51pguy/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built start-file\u001b[0m\n",
      "\u001b[34mInstalling collected packages: start-file\u001b[0m\n",
      "\u001b[34mSuccessfully installed start-file-1.0.0\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Listening at: unix:/tmp/gunicorn.sock (26)\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:49,986 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:49,986 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:50 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:50,530 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"POST /invocations HTTP/1.1\" 200 1435 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:50 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:50,530 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"POST /invocations HTTP/1.1\" 200 1435 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-07-01T14:47:51.051:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34m2024-07-01 14:47:40,788 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:40,792 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:40,793 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:40,788 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:40,792 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:40,793 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,040 INFO - sagemaker-containers - Module start_file does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:41,040 INFO - sagemaker-containers - Module start_file does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:41,041 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: start-file\n",
      "  Building wheel for start-file (setup.py): started\n",
      "  Building wheel for start-file (setup.py): finished with status 'done'\n",
      "  Created wheel for start-file: filename=start_file-1.0.0-py2.py3-none-any.whl size=3250 sha256=50578edfd4dba8b2a6bea5b2b724786f6364aa2126173953256fbb00bd71bdb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-om51pguy/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built start-file\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: start-file\n",
      "  Building wheel for start-file (setup.py): started\n",
      "  Building wheel for start-file (setup.py): finished with status 'done'\n",
      "  Created wheel for start-file: filename=start_file-1.0.0-py2.py3-none-any.whl size=3250 sha256=50578edfd4dba8b2a6bea5b2b724786f6364aa2126173953256fbb00bd71bdb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-om51pguy/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built start-file\u001b[0m\n",
      "\u001b[34mInstalling collected packages: start-file\u001b[0m\n",
      "\u001b[34mSuccessfully installed start-file-1.0.0\u001b[0m\n",
      "\u001b[35mInstalling collected packages: start-file\u001b[0m\n",
      "\u001b[35mSuccessfully installed start-file-1.0.0\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Listening at: unix:/tmp/gunicorn.sock (26)\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [26] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-07-01 14:47:43 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35m[2024-07-01 14:47:43 +0000] [26] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2024-07-01 14:47:43 +0000] [26] [INFO] Listening at: unix:/tmp/gunicorn.sock (26)\u001b[0m\n",
      "\u001b[35m[2024-07-01 14:47:43 +0000] [26] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2024-07-01 14:47:43 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2024-07-01 14:47:43 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:49,986 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:49,986 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:50 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024-07-01 14:47:50,530 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"POST /invocations HTTP/1.1\" 200 1435 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:50 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024-07-01 14:47:50,530 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Jul/2024:14:47:51 +0000] \"POST /invocations HTTP/1.1\" 200 1435 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-07-01T14:47:51.051:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the batch transform job\n",
    "transformer.transform(\n",
    "    data=input_path, # Path where the input is stored\n",
    "    content_type='text/csv', # It is neccessary because csv is not default format\n",
    "    split_type='Line' # Each line equals one observation\n",
    ")\n",
    "\n",
    "# Wait for the transform job to complete\n",
    "transformer.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887d7724-a8bf-4acb-9e41-31103fc4e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "import os\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f07cdf-a77c-4c1a-8a58-e73df6c4b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5804dbc6-bd9b-4b92-bb01-5543e054c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"05_full_pipeline\", exist_ok=True) # Create folder for training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96976fb0-f22d-4a0c-9f2a-0b6aaf1823d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 05_full_pipeline/processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 05_full_pipeline/processing.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    iris = datasets.load_iris()\n",
    "    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "    df[\"class\"] = pd.Series(iris.target)\n",
    "    df = df[df['class'].isin([0, 1])] # Lets keep only class 0 and 1 to have binary classification\n",
    "    df = df[[list(df.columns)[-1]] + list(df.columns)[:-1]] # Reorder target as the first column\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.33, random_state=42, stratify=df[\"class\"])\n",
    "    \n",
    "    iris_train = train_df.to_numpy()\n",
    "    np.savetxt('/opt/ml/processing/output/train/iris_train.csv', iris_train, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')\n",
    "    \n",
    "    iris_test = test_df.to_numpy()\n",
    "    np.savetxt('/opt/ml/processing/output/test/iris_test.csv', iris_test, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')\n",
    "    \n",
    "    iris_inference = test_df.iloc[:, 1:].to_numpy()\n",
    "    np.savetxt('/opt/ml/processing/output/inference/iris_inference.csv', iris_inference, delimiter=',', fmt='%1.3f, %1.3f, %1.3f, %1.3f')\n",
    "    \n",
    "    column_names_list = ','.join(df.columns)\n",
    "    with open('/opt/ml/processing/output/column_names.csv', 'w') as file:\n",
    "        file.write(column_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4d6553-a047-4e01-8444-781739786e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=1,\n",
    "    base_job_name=\"05-full-pipeline\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8825d4-a4ce-479c-88d2-580066ef2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination='s3://sagemaker-bucket-ds/PIPELINE/05-full-pipeline/train'),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination='s3://sagemaker-bucket-ds/PIPELINE/05-full-pipeline/test'),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"inference\",\n",
    "            source=\"/opt/ml/processing/output/inference\",\n",
    "            destination='s3://sagemaker-bucket-ds/PIPELINE/05-full-pipeline/inference'),        \n",
    "\n",
    "    ],\n",
    "    code=\"05_full_pipeline/processing.py\",\n",
    ") \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    step_args=processor_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c7ab43-7cc7-4aa1-8cb2-8eeeffe4ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 05_full_pipeline/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 05_full_pipeline/train.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_dir = os.environ['SM_MODEL_DIR'] # Folder where model must be saved\n",
    "    train_dir = os.environ['SM_CHANNEL_TRAIN'] # Folder where train data is stored\n",
    "\n",
    "    # Lets assume there is only one training file\n",
    "    train_file_name = os.listdir(train_dir)[0]\n",
    "    train_file_path = os.path.join(train_dir, train_file_name)\n",
    "    \n",
    "    train_data = pd.read_csv(train_file_path, header=None, engine=\"python\")\n",
    "\n",
    "    # labels are in the first column\n",
    "    train_y = train_data.iloc[:, 0]\n",
    "    train_X = train_data.iloc[:, 1:]  \n",
    "\n",
    "    # Train the model\n",
    "    # Hyperparameters are hardcoded\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=30)\n",
    "    clf = clf.fit(train_X, train_y)\n",
    "\n",
    "    # Save model object\n",
    "    joblib.dump(clf, os.path.join(model_dir, \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fd1ff8-584a-4a32-902a-26c0919bbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn = SKLearn(\n",
    "    entry_point='train.py', # The file with the training code\n",
    "    source_dir='05_full_pipeline', # The folder with the training code\n",
    "    framework_version='1.2-1', # Version of SKLearn which will be used\n",
    "    instance_type='ml.m5.large', # Instance type that wil be used\n",
    "    role=role, # Role that will be used during execution\n",
    "    sagemaker_session=pipeline_session, \n",
    "    base_job_name='05_full_pipeline' # Name of the training job. Timestamp will be added as suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819e22f7-f540-456f-beee-246fa3bd5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = sklearn.fit({\"train\": step_process.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2e1648-8685-4667-9914-b3f2718789c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"SimpleTrain\",\n",
    "    step_args = train_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372667f9-faec-40d8-b5c2-901579ef8d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 05_full_pipeline/start_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 05_full_pipeline/start_file.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# There is no default function to load the model\n",
    "# Without this function the job will fail!\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "# There is a default function to calculate the predictions.\n",
    "# It calculates the class 0/1 instead of probability\n",
    "# That is why we should override it with a custom function\n",
    "def predict_fn(input_data, model):\n",
    "    pred_prob = model.predict_proba(input_data)\n",
    "    return pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b02de8d-9479-4290-a153-3bbcf75c1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SKLearnModel\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    entry_point='start_file.py', # The file with the training code\n",
    "    source_dir=\"05_full_pipeline\", # The folder with the training code\n",
    "    role=role,\n",
    "    framework_version='1.2-1',  # Replace with the appropriate sklearn version\n",
    "    sagemaker_session=pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fbe9b4-c799-4ae6-b147-5bbd019a3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_create_model = ModelStep(\n",
    "   name=\"MyModelCreationStep\",\n",
    "   step_args=sklearn_model.create(instance_type=\"ml.m5.large\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70af832a-60b1-4681-8261-a86e1da75c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    output_path=f\"s3://sagemaker-bucket-ds/PIPELINE/05-full-pipeline/INFERENCE_OUTPUT/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a963a4-8585-4a0e-91da-1648dab54d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_transform = TransformStep(\n",
    "    name=\"MyTransformStep\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        data=step_process.properties.ProcessingOutputConfig.Outputs['inference'].S3Output.S3Uri,\n",
    "        content_type='text/csv', # It is neccessary because csv is not default format\n",
    "        split_type='Line' # Each line equals one observation)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aab9e12-dd93-477f-8856-10497a208653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = f\"05-full-pipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[step_process, step_train, step_create_model, step_transform],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d48f7f59-4a06-41d8-b9a6-074f16e8ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:211125740051:pipeline/05-full-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '7cc90bbc-0cd6-4236-bb1d-6617b064523f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7cc90bbc-0cd6-4236-bb1d-6617b064523f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '84',\n",
       "   'date': 'Thu, 11 Jul 2024 13:51:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe111fc-2f8c-47d8-9d81-5d4ebad2fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

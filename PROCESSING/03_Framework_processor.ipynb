{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dad1d04-2128-4a13-affa-d652d6de88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96275145-9a32-4fc3-aca3-4488d8b740f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "167a4bff-c010-4de8-a6c4-0ece1268e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"03_framework_processor\", exist_ok=True) # Create folder for training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52117782-c272-4c98-ba4b-0226a0ee4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 03_framework_processor/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile 03_framework_processor/requirements.txt\n",
    "torch==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3894a537-ea97-46e1-9bbd-5957ebe8e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 03_framework_processor/sample_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile 03_framework_processor/sample_data.csv\n",
    "a,b,c\n",
    "2,3,4\n",
    "5,6,7\n",
    "8,9,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e413512b-cea4-4ad0-9201-151dc7519696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 03_framework_processor/process_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 03_framework_processor/process_data.py\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch # this is only to make sure that torch was installed\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(torch.__version__) # check the version of torch\n",
    "\n",
    "    for key, value in os.environ.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    input_path = \"/opt/ml/processing/input/myinput/\"\n",
    "    output_path = '/opt/ml/processing/output/'\n",
    "\n",
    "    input_file_path = os.path.join(input_path, \"sample_data.csv\")\n",
    "    output_file_path = os.path.join(output_path, \"output.csv\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Calculate the sum of all columns\n",
    "    column_sums = df.sum()\n",
    "    \n",
    "    # Store the sums in a text file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for column, sum_value in column_sums.items():\n",
    "            f.write(f'{column}: {sum_value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dc5eb85-7cc5-4d2b-8e79-9b9167309ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# Define the files to include in the tar.gz archive\n",
    "files = ['03_framework_processor/process_data.py', '03_framework_processor/requirements.txt']\n",
    "\n",
    "# Create a tar.gz archive\n",
    "with tarfile.open('03_framework_processor/sourcedir.tar.gz', 'w:gz') as tar:\n",
    "    for file in files:\n",
    "        tar.add(file, arcname=file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c03ba58f-56f8-4236-841e-0d33e1c8c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: 03_framework_processor/sourcedir.tar.gz to s3://sagemaker-bucket-ds/PROCESSING/03_CODE/sourcedir.tar.gz\n",
      "upload: 03_framework_processor/sample_data.csv to s3://sagemaker-bucket-ds/PROCESSING/03_INPUT/sample_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 03_framework_processor/sourcedir.tar.gz s3://sagemaker-bucket-ds/PROCESSING/03_CODE/\n",
    "!aws s3 cp 03_framework_processor/sample_data.csv s3://sagemaker-bucket-ds/PROCESSING/03_INPUT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14d9aed7-4393-46a6-b0ca-11902e636366",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "framework_version_str = \"0.20.0\"\n",
    "\n",
    "script_processor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version=framework_version_str,\n",
    "    base_job_name=\"03-processing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1caaa053-b2f5-4685-8db2-6ae60008fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Processing Inputs and Outputs\n",
    "processing_inputs = [\n",
    "\n",
    "    ProcessingInput(\n",
    "        source='s3://sagemaker-bucket-ds/PROCESSING/03_INPUT/',\n",
    "        destination='/opt/ml/processing/input/myinput/',\n",
    "        input_name='INPUT1'\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        source='/opt/ml/processing/output/',\n",
    "        destination='s3://sagemaker-bucket-ds/PROCESSING/03_OUTPUT/',\n",
    "        output_name='OUTPUT1'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8716fb-47a9-4627-ba0f-27ab9146592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded s3://sagemaker-bucket-ds/PROCESSING/03_CODE/sourcedir.tar.gz to s3://sagemaker-bucket-ds/PROCESSING/03_CODE/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-bucket-ds/PROCESSING/03_CODE/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name 03-processing-2024-07-10-15-05-27-452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................."
     ]
    }
   ],
   "source": [
    "# Run the Processing Job\n",
    "script_processor.run(\n",
    "    code='process_data.py',\n",
    "    source_dir = \"s3://sagemaker-bucket-ds/PROCESSING/03_CODE/sourcedir.tar.gz\", # This is the file that contains codes and requirements\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
